{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2Seq Chatbot with Attention\n",
    "\n",
    "#### Members' Names: Bilal Majeed and Sandhya Prakash\n",
    "\n",
    "#### Members' Emails: bmajeed@ryerson.ca and ksandhya@ryerson.ca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction:\n",
    "\n",
    "#### Problem Description:\n",
    "\n",
    "Previously, chatbots have been developed using hand-written rules, making models static. With the recent focus in the area of deep learning and natural language processing (NLP), there have been several advancements in the space. For example, Sequence to Sequence (seq2seq) models use recurrent neural networks to solve complex language problems. The general architecture consists of an encoder and a decoder, each being stacks of LSTM or GRU layers. But, Seq2Seq models lack the ability to work with larger sentences because all information from the input sentence is required to be encoded into a fixed length vector, and is sequentially passed until the output is produced. Therefore, knowledge of the input is slowly lost throughout the prediction process.\n",
    "\n",
    "#### Context of the Problem:\n",
    "\n",
    "Text generation is a important topic is NLP which includes different applications, e.g., machine translation, caption generation, speech to text, and chatbots. Hence, solving issues identified in any one application of text generation is beneficial as it can be applied to other applications. For businesses, any models that are to be adopted need to be effective and scalable. With rule-based models, there is a lack of effectiveness and scalability, while with vanilla seq2seq models, there is an issue with effectiveness as input and output sizes increases. The Seq2Seq works well but the aim is to strengthen the performance of this model on more complex tasks with longer input and output sequences.\n",
    "\n",
    "#### Limitation About other Approaches:\n",
    "\n",
    "Rule-based models: A pattern and a template are written, so that when pattern is seen in the input, the chatbot replies with one of the templates. The pattern matching is not effective and rule-based chatbots suffer when a pattern is not recognized. Also, it is time consuming and difficult to write the rules manually.\n",
    "\n",
    "Retreival-based models: Similar to rule-based models, there is a set of responses made available to the chatbot. Based on the provided input, the chatbot selects the most appropriate response from a list. This is useful as there are no issues with grammar but this fails when unseen inputs are provided. \n",
    "\n",
    "Vaniall seq2seq models: A response, word by word based on the input and because of this, the responses generated can include grammatical errors. Once they are trained, they perform well in terms of handling previously unseen inputs. But, there is a bottle neck as it is difficult to encode the input sequence into a single fixed-length vector.\n",
    "\n",
    "#### Solution:\n",
    "\n",
    "To improve the seq2seq model and make it more robust, during training, an attention mechanism is included to gather context for each input word, allowing the decoder to have more information about each part of the input sentence. To generate the next word in the output, the context from the user input and the generated output so far is used to calculate the output with \"attention\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "| Reference | Explanation |  Dataset/Input | Weakness\n",
    "| --- | --- | --- | --- |\n",
    "| Sutskever et al. [2] | Utilized a multilayered Long Short-Term Memory (LSTM) to map the input sequence to a vector of a fixed dimensionality, and then another deep LSTM to decode the target sequence from the vector. | WMT'14 English to French | Degredation in performance after input length of 35\n",
    "| Abonia Sojasingarayar [3] | Trained an attention based sequence to sequence model using LSTM to predict an output sentence given a user input | Cornell Movie Subtitle Corpus | Worked well but processing power caused issues in training and hyperparamter optimization\n",
    "| Luong et al. [4] | Focused on discussing a global approach which always attends to all source words and a local one that only looks at a subset of source words at a time | WMT'14 English to French | Compared to the alignment visualizations in (Bahdanau et al., 2015), alignment patterns are not as sharp.\n",
    "\n",
    "Instead of using the attention described in [3], the paper suggested using Luong attention as a next step, so we used the global attention mechanism described in [4]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methodology\n",
    "\n",
    "This paper focuses on using a encoder-decoder model with an attention mechanism that allows the decoder to selectively look at the input sequence while decoding. This helps counter the bottleneck mentioned in the limitations of vaniall seq2seq models above. The vanilla seq2seq model for a chatbot accepts an input from a user, cleans the input, encodes the input using the trained model, and decodes hidden states to produce a predicted reply.\n",
    "\n",
    "#### Data Prepartion\n",
    "\n",
    "The data consists of 2 files: movie lines and groups of conversations using those lines. Each line is split by a new line character and each column is split by '+++$+++'. \n",
    "- Split movie_lines file and store is a list with all columns (available columns)\n",
    "- Data size is limited to 20000 rows due to hardware constrains and is stored in dictionary of line_id, line pairs\n",
    "- Coversation lines are stored in dictionary of conversation_id, list of lines pairs\n",
    "- Generate **model input**  data using conversations, example:\n",
    "    - Conversation: Lines 147, 148, 149\n",
    "    - Input: Lines 147, 148\n",
    "    - Output: Lines 148, 149\n",
    "    - Add **'BOS'** and **'EOS'** tags to the output lines \n",
    "    - The inputs and outputs are cleaned to get the best possible vocabulary\n",
    "    - Inputs and outputs are converted to sequences: [\"Hello\"] --> [149] if 'Hello' is at index 149 in the vocabulary\n",
    "    - Inputs and outputs are padded to the calculated max length of inputs and outputs: [149, 0, 0, 0] if max length is 4\n",
    "- Generate **model output** data:\n",
    "    - Remove **'BOS'** tag, convert to sequences, and pad to the max length of outputs\n",
    "    - Use to_categorical to turn to a matrix: [149, ...] --> [[0, ..., 1, 0, ..., 0], ...] (1 on the 149th element of the list)\n",
    "    - The tag is removed so that the model learns that given **'BOS'** in the decoder, the output word is the next word in the sentence\n",
    "\n",
    "#### Model Building (Encoder-Decoder)\n",
    "\n",
    "The model used is a encoder-decoder model with LSTM layers and an attention mechanism.\n",
    "\n",
    "![Seq2Seq](Artifacts/LSTM_encoder_decoder.png \"Seq2Seq Model\")\n",
    "- Encoder:\n",
    "    - Embedding and LSTM layers with 256 units outputting overall sequence output and encoder states (thought vector in figure above)\n",
    "- Decoder:\n",
    "    - Embedding and LSTM layers with 256 units outputting overall sequence output and decoder states\n",
    "    - Encoder states from the encoder are used as initial states of the decoder \n",
    "\n",
    "#### Model Building (Attention)\n",
    "![Global Attention](Artifacts/seqseq_globalattention.png \"Global Attention\")\n",
    "- The dot product of the encoder overall sequence output and the decoder outputs with the softmax generates the attention vector (global align weights in figure above)\n",
    "    - This vector helps the current decoder state keep track of the overall input\n",
    "- The dot product of the attention vector (global align weights) and the encoder outputs generates the context vector (context vector in figure above)\n",
    "- The context vector and the decoder output are then concatenated, and used as an input to a dense layer for the final output vector of vocabulary size\n",
    "\n",
    "#### Inference Model and Predictions\n",
    "- Requires the generation of models based on the trained models:\n",
    "    - Encoder uses the encoder inputs and outputs the encoder states defined in the model building\n",
    "    - Decoder uses the current states (starts with encoder states) with the current word (starts with 'BOS') and outputs the decoder states\n",
    "- Predictions use the outputs from the inference encoder and decoder model:\n",
    "    - Runs till loop breaks when user says 'quit'\n",
    "    - Preprocess user given input and run encoder to get encoder states\n",
    "    - Set current word to 'BOS' and preprocess current word \n",
    "    - Run generated prediction loop until 'EOS' is seen or max length of output is reached\n",
    "        - Input current word and current states to decoder model to get decoder states\n",
    "        - Use similar attention mechanism defined in model\n",
    "        - Use dense layer from trained model for final prediction\n",
    "        - Find predicted word in vocabular and concatenate to predicted output\n",
    "        - Set current word to predicted word, and set current state to decoder states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing libraries\n",
    "import codecs \n",
    "import re\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# network libraries\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM, TimeDistributed\n",
    "from keras.layers import dot\n",
    "from keras.layers import concatenate\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Lines Using Data File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total lines in dataset: 304714\n",
      "Total selected lines from dataset: 40000\n"
     ]
    }
   ],
   "source": [
    "def load_file ():\n",
    "    data = []\n",
    "    \n",
    "    with codecs.open(\"movie_lines.txt\", \"rb\", encoding = \"utf-8\", errors = \"ignore\") as f:\n",
    "        # split rows by new line\n",
    "        rows = f.read().split(\"\\n\")\n",
    "        for row in rows:\n",
    "            # split columns by '+++$+++'\n",
    "            data.append(row.split(\" +++$+++ \"))\n",
    "            \n",
    "    return data\n",
    "\n",
    "data = load_file()\n",
    "total_lines = len(data)\n",
    "print(f\"Total lines in dataset: {total_lines}\")\n",
    "\n",
    "def load_lines (data):\n",
    "    sentences = {}\n",
    "\n",
    "    for row in data[:40000]:\n",
    "        # check if all columns are available\n",
    "        if len(row) > 4:\n",
    "            # use line number as key and sentence as value    \n",
    "            sentences[int(row[0][1:])] = row[4]\n",
    "            \n",
    "    # sort dictionary by line number\n",
    "    return dict(sorted(sentences.items()))\n",
    "\n",
    "lines = load_lines(data)\n",
    "total_lines = len(list(lines.keys()))\n",
    "print(f\"Total selected lines from dataset: {total_lines}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Conversations Using Data File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_conversations ():\n",
    "    conversations = {}\n",
    "    conversation_number = 1\n",
    "    \n",
    "    with codecs.open(\"movie_conversations.txt\", \"rb\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        # split rows by new line\n",
    "        rows = f.read().split(\"\\n\")\n",
    "        for row in rows:\n",
    "            # split columns by '+++$+++', only get lines per conversation, remove \"[\" and \"]\"\n",
    "            conversation_ids = row.split(\" +++$+++ \")[-1][1:-1]\n",
    "            line_ids = []\n",
    "            # for each line in conversation\n",
    "            for line_id in conversation_ids.split(\",\"):\n",
    "                # remove extra quotes\n",
    "                line_id = line_id.replace(\"'\", \"\").strip()\n",
    "                line_ids += [line_id[1:]]\n",
    "                \n",
    "            # store list of lines\n",
    "            conversations[conversation_number] = line_ids\n",
    "            conversation_number += 1\n",
    "            \n",
    "    return conversations\n",
    "\n",
    "conversation_dictionary = load_conversations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine Lines and Conversations to Generate Input and Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_inputs_outputs (conversations_dictionary, lines, maxlen):\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    \n",
    "    for current_conv in conversations_dictionary.values():\n",
    "        # make sure that each conversation contains atleast 2 lines\n",
    "        if len(current_conv) > 2:\n",
    "            current_conv = current_conv[:-1]\n",
    "        # convert questions and answers to the list of tuples\n",
    "        for i in range(0, len(current_conv)):\n",
    "            if len(current_conv) - i > 1:\n",
    "                # add to inputs and outputs if conversation is in selected lines\n",
    "                # to reduce output and input length, a cutoff is provided\n",
    "                try:\n",
    "                    if len(lines[int(current_conv[i])].split()) <= maxlen and \\\n",
    "                        len(lines[int(current_conv[i + 1])].split()) <= maxlen:\n",
    "                        inputs += [lines[int(current_conv[i])]]\n",
    "                        outputs += [lines[int(current_conv[i + 1])]]\n",
    "                except:\n",
    "                    continue\n",
    "    \n",
    "    return inputs, outputs\n",
    "\n",
    "inputs, outputs = generate_inputs_outputs(conversation_dictionary, lines, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean Lines and Add Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs in dataset: 17635\n",
      "Outputs in dataset: 17635\n"
     ]
    }
   ],
   "source": [
    "def replace_text (sentence):\n",
    "    sentence = sentence.lower()\n",
    "    \n",
    "    sentence = re.sub(r\"i'm\", \"i am\", sentence)\n",
    "    sentence = re.sub(r\"he's\", \"he is\", sentence)\n",
    "    sentence = re.sub(r\"she's\", \"she is\", sentence)\n",
    "    sentence = re.sub(r\"it's\", \"it is\", sentence)\n",
    "    sentence = re.sub(r\"that's\", \"that is\", sentence)\n",
    "    sentence = re.sub(r\"what's\", \"that is\", sentence)\n",
    "    sentence = re.sub(r\"where's\", \"where is\", sentence)\n",
    "    sentence = re.sub(r\"how's\", \"how is\", sentence)\n",
    "    sentence = re.sub(r\"\\'ll\", \" will\", sentence)\n",
    "    sentence = re.sub(r\"\\'ve\", \" have\", sentence)\n",
    "    sentence = re.sub(r\"\\'re\", \" are\", sentence)\n",
    "    sentence = re.sub(r\"\\'d\", \" would\", sentence)\n",
    "    sentence = re.sub(r\"\\'re\", \" are\", sentence)\n",
    "    sentence = re.sub(r\"won't\", \"will not\", sentence)\n",
    "    sentence = re.sub(r\"can't\", \"cannot\", sentence)\n",
    "    sentence = re.sub(r\"c'mon\", \"come on\", sentence)\n",
    "    sentence = re.sub(r\"n't\", \" not\", sentence)\n",
    "    sentence = re.sub(r\"n'\", \"ng\", sentence)\n",
    "    sentence = re.sub(r\"'bout\", \"about\", sentence)\n",
    "    sentence = re.sub(r\"'til\", \"until\", sentence)\n",
    "    sentence = re.sub(r\"  \", \" \", sentence)\n",
    "    sentence = re.sub(r\"[-()\\\"#/@;:<>{}`+=~|.!?,]\", \"\", sentence)\n",
    "    \n",
    "    return sentence\n",
    "\n",
    "def preprocess_inputs_outputs (inputs, outputs):\n",
    "    \n",
    "    for i in range(len(inputs)):\n",
    "        inputs[i] = replace_text(inputs[i])\n",
    "    # add <BOS> and <EOS> tags for output to keep track of start and end\n",
    "    for i in range(len(outputs)):\n",
    "        outputs[i] = '<BOS> ' + replace_text(outputs[i]) + ' <EOS>'\n",
    "    \n",
    "    return inputs, outputs\n",
    "    \n",
    "inputs, outputs = preprocess_inputs_outputs(inputs, outputs)\n",
    "print(f\"Inputs in dataset: {len(inputs)}\")\n",
    "print(f\"Outputs in dataset: {len(outputs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform Sentences to Padded Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 11903\n",
      "Maximum Input Length: 25\n",
      "Maximum Output Length: 27\n"
     ]
    }
   ],
   "source": [
    "# give symbols and numbers that are not needed to the tokenizer\n",
    "filtering_pattern = '!\"#$%&()*+,-./:;=?@[\\]^_`{|}~\\t\\n\\'0123456789'\n",
    "tokenizer = Tokenizer(filters = filtering_pattern)\n",
    "# this will generate vocab on all inputs and outputs\n",
    "tokenizer.fit_on_texts(inputs + outputs)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(f\"Vocabulary size: {vocab_size}\")\n",
    "\n",
    "# tokenize and pad inputs\n",
    "tokenized_inputs = tokenizer.texts_to_sequences(inputs)\n",
    "maxlen_inputs = max([len(x) for x in tokenized_inputs])\n",
    "print(f\"Maximum Input Length: {maxlen_inputs}\")\n",
    "encoder_input_data = pad_sequences(tokenized_inputs, maxlen = maxlen_inputs, padding = 'post')\n",
    "\n",
    "# tokenize and pad outputs\n",
    "tokenized_outputs = tokenizer.texts_to_sequences(outputs)\n",
    "maxlen_outputs = max([len(x) for x in tokenized_outputs])\n",
    "print(f\"Maximum Output Length: {maxlen_outputs}\")\n",
    "decoder_input_data = pad_sequences(tokenized_outputs, maxlen = maxlen_outputs, padding = 'post')\n",
    "\n",
    "# remove '<BOS>' from every output\n",
    "# this will be used as the next word to be predcited since '<BOS>' will be given\n",
    "for i in range(len(tokenized_outputs)):\n",
    "    tokenized_outputs[i] = tokenized_outputs[i][1:]\n",
    "# pad and create a matrix based on vocabulary\n",
    "padded_outputs = pad_sequences(tokenized_outputs, maxlen = maxlen_outputs, padding = 'post')\n",
    "decoder_output_data = to_categorical(padded_outputs, vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seq2Seq Model with Attention for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 256)    3047168     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 256)    3047168     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, None, 256),  525312      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 256),  525312      embedding_1[0][0]                \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "dot (Dot)                       (None, None, None)   0           lstm_1[0][0]                     \n",
      "                                                                 lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, None, None)   0           dot[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, None, 256)    0           activation[0][0]                 \n",
      "                                                                 lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, None, 512)    0           dot_1[0][0]                      \n",
      "                                                                 lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, None, 11903)  6106239     concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 13,251,199\n",
      "Trainable params: 13,251,199\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# encoder model with LSTM layer with 256 units, returning outputs and states\n",
    "enc_inputs = Input(shape=(None,))\n",
    "enc_embedding = Embedding(vocab_size, 256, mask_zero = True)(enc_inputs)\n",
    "enc_lstm = LSTM(256, return_sequences = True, return_state = True)\n",
    "enc_outputs, enc_state_h, enc_state_c = enc_lstm(enc_embedding)\n",
    "enc_states = [enc_state_h, enc_state_c]\n",
    "enc_outputs = enc_outputs\n",
    "\n",
    "# decoder model with LSTM layer with 256 units, returning outputs and states\n",
    "dec_inputs = Input(shape = (None,))\n",
    "dec_embedding = Embedding(vocab_size, 256, mask_zero = True)(dec_inputs)\n",
    "dec_lstm = LSTM(256, return_state = True, return_sequences = True)\n",
    "dec_outputs, dec_state_h, dec_state_c = dec_lstm(dec_embedding, initial_state = enc_states)\n",
    "\n",
    "# connect decoder and encoder outputs to generate an attention vector with softmax applied\n",
    "attention = dot([dec_outputs, enc_outputs], axes = [2, 2])\n",
    "attention = Activation('softmax')(attention)\n",
    "# connect the attention vector and encoder outputs to generate context vector\n",
    "context = dot([attention, enc_outputs], axes = [2, 1])\n",
    "# connect context vector and decoder outputs to use as input for dense layer\n",
    "dec_attention_outputs = concatenate([context, dec_outputs])\n",
    "\n",
    "# use decoder outputs concatenated with the context vector to output final prediction\n",
    "dec_dense = TimeDistributed(Dense(vocab_size, activation = 'softmax'))\n",
    "output = dec_dense(dec_attention_outputs)\n",
    "\n",
    "# generate and compile model\n",
    "model = Model([enc_inputs, dec_inputs], output)\n",
    "model.compile(optimizer = \"adam\", loss = 'categorical_crossentropy', metrics = [\"accuracy\"])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "138/138 [==============================] - 191s 1s/step - loss: 2.4289 - accuracy: 0.1411\n",
      "Epoch 2/30\n",
      "138/138 [==============================] - 183s 1s/step - loss: 1.7578 - accuracy: 0.2267\n",
      "Epoch 3/30\n",
      "138/138 [==============================] - 177s 1s/step - loss: 1.6591 - accuracy: 0.2502\n",
      "Epoch 4/30\n",
      "138/138 [==============================] - 180s 1s/step - loss: 1.5934 - accuracy: 0.2729\n",
      "Epoch 5/30\n",
      "138/138 [==============================] - 181s 1s/step - loss: 1.5401 - accuracy: 0.2862\n",
      "Epoch 6/30\n",
      "138/138 [==============================] - 182s 1s/step - loss: 1.4702 - accuracy: 0.2989\n",
      "Epoch 7/30\n",
      "138/138 [==============================] - 184s 1s/step - loss: 1.4383 - accuracy: 0.3042\n",
      "Epoch 8/30\n",
      "138/138 [==============================] - 180s 1s/step - loss: 1.4108 - accuracy: 0.3068\n",
      "Epoch 9/30\n",
      "138/138 [==============================] - 181s 1s/step - loss: 1.3652 - accuracy: 0.3145\n",
      "Epoch 10/30\n",
      "138/138 [==============================] - 182s 1s/step - loss: 1.3205 - accuracy: 0.3209\n",
      "Epoch 11/30\n",
      "138/138 [==============================] - 183s 1s/step - loss: 1.3082 - accuracy: 0.3241\n",
      "Epoch 12/30\n",
      "138/138 [==============================] - 184s 1s/step - loss: 1.2646 - accuracy: 0.3318\n",
      "Epoch 13/30\n",
      "138/138 [==============================] - 181s 1s/step - loss: 1.2158 - accuracy: 0.3427\n",
      "Epoch 14/30\n",
      "138/138 [==============================] - 185s 1s/step - loss: 1.1720 - accuracy: 0.3554\n",
      "Epoch 15/30\n",
      "138/138 [==============================] - 183s 1s/step - loss: 1.1204 - accuracy: 0.3697\n",
      "Epoch 16/30\n",
      "138/138 [==============================] - 184s 1s/step - loss: 1.0871 - accuracy: 0.3848\n",
      "Epoch 17/30\n",
      "138/138 [==============================] - 183s 1s/step - loss: 1.0392 - accuracy: 0.4024\n",
      "Epoch 18/30\n",
      "138/138 [==============================] - 182s 1s/step - loss: 0.9978 - accuracy: 0.4198\n",
      "Epoch 19/30\n",
      "138/138 [==============================] - 184s 1s/step - loss: 0.9510 - accuracy: 0.4384\n",
      "Epoch 20/30\n",
      "138/138 [==============================] - 184s 1s/step - loss: 0.9214 - accuracy: 0.4524\n",
      "Epoch 21/30\n",
      "138/138 [==============================] - 184s 1s/step - loss: 0.8800 - accuracy: 0.4705\n",
      "Epoch 22/30\n",
      "138/138 [==============================] - 183s 1s/step - loss: 0.8452 - accuracy: 0.4862\n",
      "Epoch 23/30\n",
      "138/138 [==============================] - 184s 1s/step - loss: 0.8084 - accuracy: 0.5031\n",
      "Epoch 24/30\n",
      "138/138 [==============================] - 185s 1s/step - loss: 0.7756 - accuracy: 0.5214\n",
      "Epoch 25/30\n",
      "138/138 [==============================] - 185s 1s/step - loss: 0.7479 - accuracy: 0.5360\n",
      "Epoch 26/30\n",
      "138/138 [==============================] - 183s 1s/step - loss: 0.7139 - accuracy: 0.5519\n",
      "Epoch 27/30\n",
      "138/138 [==============================] - 184s 1s/step - loss: 0.6838 - accuracy: 0.5708\n",
      "Epoch 28/30\n",
      "138/138 [==============================] - 183s 1s/step - loss: 0.6616 - accuracy: 0.5837\n",
      "Epoch 29/30\n",
      "138/138 [==============================] - 179s 1s/step - loss: 0.6279 - accuracy: 0.6038\n",
      "Epoch 30/30\n",
      "138/138 [==============================] - 183s 1s/step - loss: 0.6095 - accuracy: 0.6173\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([encoder_input_data, decoder_input_data], decoder_output_data, \n",
    "                    batch_size = 128, epochs = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seq2Seq Model for Inference using Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder model using inputs and outputs defined above\n",
    "enc_model = Model(enc_inputs, [enc_outputs, enc_states])\n",
    "\n",
    "# set intputs to receive encoder model states output by enc_model\n",
    "decoder_initial_state_h = Input(shape = (256, ))\n",
    "decoder_initial_state_c = Input(shape = (256, ))\n",
    "decoder_initial_states = [decoder_initial_state_h, decoder_initial_state_c]\n",
    "# lstm layer is defined again to set up with decoder_inital_states variable because this will change \n",
    "# as predictions more forward\n",
    "decoder_outputs, decoder_state_h, decoder_state_c = dec_lstm(dec_embedding , initial_state = decoder_initial_states)\n",
    "decoder_states = [decoder_state_h, decoder_state_c]\n",
    "# decoder model using lstm layer defined above in trained model with variabled defined\n",
    "dec_model = Model([dec_inputs, decoder_initial_states], [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample Chatbot using Inference Model with Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You: Hi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: hi \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You: How are you?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: scarred for life for a little \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You: Why scarred?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: because you are a policeman \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You: Where are you from?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: helsinki which is the capital of finland \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You: Where are you going tonight?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i am going to see the other side of the hotel \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You: Why are you going to see the other side of the hotel?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: well we will see the other room or the room or the room are you \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You: why are you acting strange?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i am not in the middle of your life \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You: okay you are free to go\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: look up there later you are going to be a big evening \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You: What big evening?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: what do you mean \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You: What do you mean?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i do not know that is wrong with you \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You: Something is wrong with you\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: what do you mean \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You: Nothing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i am going to be a little girl in the spears \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You: Thanks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: you are welcome to be a crook do you want to be a crook \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You: No I don't want to be a crook\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i do not think i do not think i do not think i do not think i do not want to do \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You: now you are just not making sense\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i am not a little way for you \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You: bye\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: yeah huh \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You: quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Bye\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    # take user input\n",
    "    userinput = input('You:')\n",
    "    # if input is 'quit', return 'bye'\n",
    "    if userinput == 'quit':\n",
    "        print('Bot: ' + 'Bye')\n",
    "        break\n",
    "    \n",
    "    # preprocess user input\n",
    "    userinput = replace_text(userinput)\n",
    "    userinput = tokenizer.texts_to_sequences([userinput])\n",
    "    userinput = pad_sequences(userinput, maxlen = maxlen_inputs, padding = 'post')\n",
    "    \n",
    "    # return encoder outputs and states for given user input\n",
    "    encoder_outputs, encoder_states = enc_model.predict(userinput)\n",
    "    \n",
    "    # initialize current word as '<bos>' and encoder states as initial input states\n",
    "    current_word = '<bos>'\n",
    "    current_input_states = encoder_states\n",
    "    predicted_output = ''\n",
    "\n",
    "    for i in range(maxlen_outputs):\n",
    "        # transform current word to vocab index\n",
    "        empty_target_seq = np.zeros((1, 1))\n",
    "        empty_target_seq[0, 0] = tokenizer.word_index[current_word]\n",
    "        \n",
    "        # return decoder outputs and states for current word and current states\n",
    "        decoder_outputs, decoder_state_h, decoder_state_c = dec_model.predict([empty_target_seq] + current_input_states)\n",
    "        \n",
    "        # derive context and predict next word using decoder output with attention\n",
    "        attention_output = dot([decoder_outputs, encoder_outputs], axes=[2,2])\n",
    "        attention_output = Activation('softmax')(attention_output)\n",
    "        context_output = dot([attention_output, encoder_outputs], axes=[2,1])\n",
    "        dec_attention = concatenate([context_output, decoder_outputs])\n",
    "        final_output1 = dec_dense(dec_attention)\n",
    "\n",
    "        # find the predicted word \n",
    "        for word, idx in tokenizer.word_index.items():\n",
    "            if idx == np.argmax(final_output1):\n",
    "                next_word = word\n",
    "\n",
    "        # change the current word and current states\n",
    "        current_word = next_word\n",
    "        current_input_states = [decoder_state_h, decoder_state_c]\n",
    "\n",
    "        # break if '<eos>' is predicted\n",
    "        if next_word == '<eos>':\n",
    "            break\n",
    "        else:\n",
    "            predicted_output += next_word + ' '\n",
    "\n",
    "    print(\"Bot: \" + predicted_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion and Future Direction\n",
    "\n",
    "During this project, we learnt that a seq2seq model with attention required lots of data and processing power to train. Despite the attention mechanism implemented, the lack of training and the subset of data selected did not allow the model to perform well. Furthermore, there was no hyperparameter tuning done to the model due to the hardware requirements. Our goal with this set up was to get the model to try produce \"proper\" sentence, which it was able to do to some extent. Also, it is nearly impossible to obtain a human-human like conversation with a chatbot due to the use of a movie lines dataset.\n",
    "\n",
    "#### Future Direction\n",
    "- Better hardware to use all available data and train for more epochs, or learn to progressively train the model\n",
    "- Obtain realistic training data, not movie lines\n",
    "- BERT embeddings weights used instead of generated own embeddings\n",
    "- Learn and attempt to implement hierarchical neural attention encoder\n",
    "- Test Transformer architecture chatbot and compare results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References:\n",
    "\n",
    "[1]: Dataset collect and information about Cornell movie dialog corpus dataset; Available: https://www.cs.cornell.edu/ cristian/CornellMovieDialogsCorpus.htm\n",
    "\n",
    "[2]: Seq2Seq AI Chatbot with Attention Mechanism; Abonia Sojasingarayar; [Paper] Available: https://arxiv.org/ftp/arxiv/papers/2006/2006.02767.pdf\n",
    "\n",
    "[3]: Sequence to Sequence Learning with Neural Networks; Ilya Sutskever, Oriol Vinyals, Quoc V. Le; [Paper] Available: https://arxiv.org/pdf/1409.3215v3.pdf\n",
    "\n",
    "[4]: Effective Approaches to Attention-based Neural Machine Translation; Minh-Thang Luong, Hieu Pham, Christopher D. Manning; [Paper] Available: https://arxiv.org/pdf/1508.04025.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
