{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2Seq Chatbot with Attention\n",
    "\n",
    "#### Members' Names: Bilal Majeed and Sandhya Prakash\n",
    "\n",
    "#### Members' Emails: bmajeed@ryerson.ca and ksandhya@ryerson.ca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction:\n",
    "\n",
    "#### Problem Description:\n",
    "\n",
    "Previously, chatbots have been developed using hand-written rules, making models static. With the recent focus in the area of deep learning and natural language processing (NLP), there have been several advancements in the space. For example, Sequence to Sequence (seq2seq) models use recurrent neural networks to solve complex language problems. The general architecture consists of an encoder and a decoder, each being stacks of LSTM or GRU layers. But, Seq2Seq models lack the ability to work with larger sentences because all information from the input sentence is required to be encoded into a fixed length vector, and is sequentially passed until the output is produced. Therefore, knowledge of the input is slowly lost throughout the prediction process.\n",
    "\n",
    "#### Context of the Problem:\n",
    "\n",
    "Text generation is a important topic is NLP which includes different applications, e.g., machine translation, caption generation, speech to text, and chatbots. Hence, solving issues identified in any one application of text generation is beneficial as it can be applied to other applications. For businesses, any models that are to be adopted need to be effective and scalable. With rule-based models, there is a lack of effectiveness and scalability, while with vanilla seq2seq models, there is an issue with effectiveness as input and output sizes increases. The Seq2Seq works well but the aim is to strengthen the performance of this model on more complex tasks with longer input and output sequences.\n",
    "\n",
    "#### Limitation About other Approaches:\n",
    "\n",
    "Rule-based models: A pattern and a template are written, so that when pattern is seen in the input, the chatbot replies with one of the templates. The pattern matching is not effective and rule-based chatbots suffer when a pattern is not recognized. Also, it is time consuming and difficult to write the rules manually.\n",
    "\n",
    "Retreival-based models: Similar to rule-based models, there is a set of responses made available to the chatbot. Based on the provided input, the chatbot selects the most appropriate response from a list. This is useful as there are no issues with grammar but this fails when unseen inputs are provided. \n",
    "\n",
    "Vaniall seq2seq models: A response, word by word based on the input and because of this, the responses generated can include grammatical errors. Once they are trained, they perform well in terms of handling previously unseen inputs. But, there is a bottle neck as it is difficult to encode the input sequence into a single fixed-length vector.\n",
    "\n",
    "#### Solution:\n",
    "\n",
    "To improve the seq2seq model and make it more robust, during training, an attention mechanism is included to gather context for each input word, allowing the decoder to have more information about each part of the input sentence. To generate the next word in the output, the context from the user input and the generated output so far is used to calculate the output with \"attention\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "| Reference | Explanation |  Dataset/Input | Weakness\n",
    "| --- | --- | --- | --- |\n",
    "| Sutskever et al. [2] | Utilized a multilayered Long Short-Term Memory (LSTM) to map the input sequence to a vector of a fixed dimensionality, and then another deep LSTM to decode the target sequence from the vector. | WMT'14 English to French | Degredation in performance after input length of 35\n",
    "| Abonia Sojasingarayar [3] | Trained an attention based sequence to sequence model using LSTM to predict an output sentence given a user input | Cornell Movie Subtitle Corpus | Worked well but processing power caused issues in training and hyperparamter optimization\n",
    "| Luong et al. [4] | Focused on discussing a global approach which always attends to all source words and a local one that only looks at a subset of source words at a time | WMT'14 English to French | Compared to the alignment visualizations in (Bahdanau et al., 2015), alignment patterns are not as sharp.\n",
    "\n",
    "Instead of using the attention described in [3], the paper suggested using Luong attention as a next step, so we used the global attention mechanism described in [4]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methodology\n",
    "\n",
    "This paper focuses on using a encoder-decoder model with an attention mechanism that allows the decoder to selectively look at the input sequence while decoding. This helps counter the bottleneck mentioned in the limitations of vaniall seq2seq models above. The vanilla seq2seq model for a chatbot accepts an input from a user, cleans the input, encodes the input using the trained model, and decodes hidden states to produce a predicted reply.\n",
    "\n",
    "#### Data Prepartion\n",
    "\n",
    "The data consists of 2 files: movie lines and groups of conversations using those lines. Each line is split by a new line character and each column is split by '+++$+++'. \n",
    "- Split movie_lines file and store is a list with all columns (available columns)\n",
    "- Data size is limited to 20000 rows due to hardware constrains and is stored in dictionary of line_id, line pairs\n",
    "- Coversation lines are stored in dictionary of conversation_id, list of lines pairs\n",
    "- Generate **model input**  data using conversations, example:\n",
    "    - Conversation: Lines 147, 148, 149\n",
    "    - Input: Lines 147, 148\n",
    "    - Output: Lines 148, 149\n",
    "    - Add **'BOS'** and **'EOS'** tags to the output lines \n",
    "    - The inputs and outputs are cleaned to get the best possible vocabulary\n",
    "    - Inputs and outputs are converted to sequences: [\"Hello\"] --> [149] if 'Hello' is at index 149 in the vocabulary\n",
    "    - Inputs and outputs are padded to the calculated max length of inputs and outputs: [149, 0, 0, 0] if max length is 4\n",
    "- Generate **model output** data:\n",
    "    - Remove **'BOS'** tag, convert to sequences, and pad to the max length of outputs\n",
    "    - Use to_categorical to turn to a matrix: [149, ...] --> [[0, ..., 1, 0, ..., 0], ...] (1 on the 149th element of the list)\n",
    "    - The tag is removed so that the model learns that given **'BOS'** in the decoder, the output word is the next word in the sentence\n",
    "\n",
    "#### Model Building (Encoder-Decoder)\n",
    "\n",
    "The model used is a encoder-decoder model with LSTM layers and an attention mechanism.\n",
    "\n",
    "![Seq2Seq](<img src="/Artifacts/LSTM_encoder_decoder.png"/> \"Seq2Seq Model\")\n",
    "- Encoder:\n",
    "    - Embedding and LSTM layers with 256 units outputting overall sequence output and encoder states (thought vector in figure above)\n",
    "- Decoder:\n",
    "    - Embedding and LSTM layers with 256 units outputting overall sequence output and decoder states\n",
    "    - Encoder states from the encoder are used as initial states of the decoder \n",
    "\n",
    "#### Model Building (Attention)\n",
    "\n",
    "![Global Attention](<img src="/Artifacts/seqseq_globalattention.png"/> \"Global Attention\")\n",
    "- The dot product of the encoder overall sequence output and the decoder outputs with the softmax generates the attention vector (global align weights in figure above)\n",
    "    - This vector helps the current decoder state keep track of the overall input\n",
    "- The dot product of the attention vector (global align weights) and the encoder outputs generates the context vector (context vector in figure above)\n",
    "- The context vector and the decoder output are then concatenated, and used as an input to a dense layer for the final output vector of vocabulary size\n",
    "\n",
    "#### Inference Model and Predictions\n",
    "- Requires the generation of models based on the trained models:\n",
    "    - Encoder uses the encoder inputs and outputs the encoder states defined in the model building\n",
    "    - Decoder uses the current states (starts with encoder states) with the current word (starts with 'BOS') and outputs the decoder states\n",
    "- Predictions use the outputs from the inference encoder and decoder model:\n",
    "    - Runs till loop breaks when user says 'quit'\n",
    "    - Preprocess user given input and run encoder to get encoder states\n",
    "    - Set current word to 'BOS' and preprocess current word \n",
    "    - Run generated prediction loop until 'EOS' is seen or max length of output is reached\n",
    "        - Input current word and current states to decoder model to get decoder states\n",
    "        - Use similar attention mechanism defined in model\n",
    "        - Use dense layer from trained model for final prediction\n",
    "        - Find predicted word in vocabular and concatenate to predicted output\n",
    "        - Set current word to predicted word, and set current state to decoder states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing libraries\n",
    "import codecs \n",
    "import re\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# network libraries\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM, TimeDistributed\n",
    "from keras.layers import dot\n",
    "from keras.layers import concatenate\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Lines Using Data File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total lines in dataset: 304714\n",
      "Total selected lines from dataset: 30000\n"
     ]
    }
   ],
   "source": [
    "def load_file ():\n",
    "    data = []\n",
    "    \n",
    "    with codecs.open(\"movie_lines.txt\", \"rb\", encoding = \"utf-8\", errors = \"ignore\") as f:\n",
    "        # split rows by new line\n",
    "        rows = f.read().split(\"\\n\")\n",
    "        for row in rows:\n",
    "            # split columns by '+++$+++'\n",
    "            data.append(row.split(\" +++$+++ \"))\n",
    "            \n",
    "    return data\n",
    "\n",
    "data = load_file()\n",
    "total_lines = len(data)\n",
    "print(f\"Total lines in dataset: {total_lines}\")\n",
    "\n",
    "def load_lines (data):\n",
    "    sentences = {}\n",
    "    \n",
    "    for row in data[:30000]:\n",
    "        # check if all columns are available\n",
    "        if len(row) > 4:\n",
    "            # use line number as key and sentence as value    \n",
    "            sentences[int(row[0][1:])] = row[4]\n",
    "            \n",
    "    # sort dictionary by line number\n",
    "    return dict(sorted(sentences.items()))\n",
    "\n",
    "lines = load_lines(data)\n",
    "total_lines = len(list(lines.keys()))\n",
    "print(f\"Total selected lines from dataset: {total_lines}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Conversations Using Data File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_conversations ():\n",
    "    conversations = {}\n",
    "    conversation_number = 1\n",
    "    \n",
    "    with codecs.open(\"movie_conversations.txt\", \"rb\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        # split rows by new line\n",
    "        rows = f.read().split(\"\\n\")\n",
    "        for row in rows:\n",
    "            # split columns by '+++$+++', only get lines per conversation, remove \"[\" and \"]\"\n",
    "            conversation_ids = row.split(\" +++$+++ \")[-1][1:-1]\n",
    "            line_ids = []\n",
    "            # for each line in conversation\n",
    "            for line_id in conversation_ids.split(\",\"):\n",
    "                # remove extra quotes\n",
    "                line_id = line_id.replace(\"'\", \"\").strip()\n",
    "                line_ids += [line_id[1:]]\n",
    "                \n",
    "            # store list of lines\n",
    "            conversations[conversation_number] = line_ids\n",
    "            conversation_number += 1\n",
    "            \n",
    "    return conversations\n",
    "\n",
    "conversation_dictionary = load_conversations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine Lines and Conversations to Generate Input and Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_inputs_outputs (conversations_dictionary, lines, maxlen):\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    \n",
    "    for current_conv in conversations_dictionary.values():\n",
    "        # make sure that each conversation contains atleast 2 lines\n",
    "        if len(current_conv) > 2:\n",
    "            current_conv = current_conv[:-1]\n",
    "        # convert questions and answers to the list of tuples\n",
    "        for i in range(0, len(current_conv)):\n",
    "            if len(current_conv) - i > 1:\n",
    "                # add to inputs and outputs if conversation is in selected lines\n",
    "                # to reduce output and input length, a cutoff is provided\n",
    "                try:\n",
    "                    if len(lines[int(current_conv[i])].split()) <= maxlen and \\\n",
    "                        len(lines[int(current_conv[i + 1])].split()) <= maxlen:\n",
    "                        inputs += [lines[int(current_conv[i])]]\n",
    "                        outputs += [lines[int(current_conv[i + 1])]]\n",
    "                except:\n",
    "                    continue\n",
    "    \n",
    "    return inputs, outputs\n",
    "\n",
    "inputs, outputs = generate_inputs_outputs(conversation_dictionary, lines, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean Lines and Add Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs in dataset: 15257\n",
      "Outputs in dataset: 15257\n"
     ]
    }
   ],
   "source": [
    "def replace_text (sentence):\n",
    "    sentence = sentence.lower()\n",
    "    \n",
    "    sentence = re.sub(r\"i'm\", \"i am\", sentence)\n",
    "    sentence = re.sub(r\"he's\", \"he is\", sentence)\n",
    "    sentence = re.sub(r\"she's\", \"she is\", sentence)\n",
    "    sentence = re.sub(r\"it's\", \"it is\", sentence)\n",
    "    sentence = re.sub(r\"that's\", \"that is\", sentence)\n",
    "    sentence = re.sub(r\"what's\", \"that is\", sentence)\n",
    "    sentence = re.sub(r\"where's\", \"where is\", sentence)\n",
    "    sentence = re.sub(r\"how's\", \"how is\", sentence)\n",
    "    sentence = re.sub(r\"\\'ll\", \" will\", sentence)\n",
    "    sentence = re.sub(r\"\\'ve\", \" have\", sentence)\n",
    "    sentence = re.sub(r\"\\'re\", \" are\", sentence)\n",
    "    sentence = re.sub(r\"\\'d\", \" would\", sentence)\n",
    "    sentence = re.sub(r\"\\'re\", \" are\", sentence)\n",
    "    sentence = re.sub(r\"won't\", \"will not\", sentence)\n",
    "    sentence = re.sub(r\"can't\", \"cannot\", sentence)\n",
    "    sentence = re.sub(r\"c'mon\", \"come on\", sentence)\n",
    "    sentence = re.sub(r\"n't\", \" not\", sentence)\n",
    "    sentence = re.sub(r\"n'\", \"ng\", sentence)\n",
    "    sentence = re.sub(r\"'bout\", \"about\", sentence)\n",
    "    sentence = re.sub(r\"'til\", \"until\", sentence)\n",
    "    sentence = re.sub(r\"  \", \" \", sentence)\n",
    "    sentence = re.sub(r\"[-()\\\"#/@;:<>{}`+=~|.!?,]\", \"\", sentence)\n",
    "    \n",
    "    return sentence\n",
    "\n",
    "def preprocess_inputs_outputs (inputs, outputs):\n",
    "    \n",
    "    for i in range(len(inputs)):\n",
    "        inputs[i] = replace_text(inputs[i])\n",
    "    # add <BOS> and <EOS> tags for output to keep track of start and end\n",
    "    for i in range(len(outputs)):\n",
    "        outputs[i] = '<BOS> ' + replace_text(outputs[i]) + ' <EOS>'\n",
    "    \n",
    "    return inputs, outputs\n",
    "    \n",
    "inputs, outputs = preprocess_inputs_outputs(inputs, outputs)\n",
    "print(f\"Inputs in dataset: {len(inputs)}\")\n",
    "print(f\"Outputs in dataset: {len(outputs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform Sentences to Padded Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 12024\n",
      "Maximum Input Length: 35\n",
      "Maximum Output Length: 37\n"
     ]
    }
   ],
   "source": [
    "# give symbols and numbers that are not needed to the tokenizer\n",
    "filtering_pattern = '!\"#$%&()*+,-./:;=?@[\\]^_`{|}~\\t\\n\\'0123456789'\n",
    "tokenizer = Tokenizer(filters = filtering_pattern)\n",
    "# this will generate vocab on all inputs and outputs\n",
    "tokenizer.fit_on_texts(inputs + outputs)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(f\"Vocabulary size: {vocab_size}\")\n",
    "\n",
    "# tokenize and pad inputs\n",
    "tokenized_inputs = tokenizer.texts_to_sequences(inputs)\n",
    "maxlen_inputs = max([len(x) for x in tokenized_inputs])\n",
    "print(f\"Maximum Input Length: {maxlen_inputs}\")\n",
    "encoder_input_data = pad_sequences(tokenized_inputs, maxlen = maxlen_inputs, padding = 'post')\n",
    "\n",
    "# tokenize and pad outputs\n",
    "tokenized_outputs = tokenizer.texts_to_sequences(outputs)\n",
    "maxlen_outputs = max([len(x) for x in tokenized_outputs])\n",
    "print(f\"Maximum Output Length: {maxlen_outputs}\")\n",
    "decoder_input_data = pad_sequences(tokenized_outputs, maxlen = maxlen_outputs, padding = 'post')\n",
    "\n",
    "# remove '<BOS>' from every output\n",
    "# this will be used as the next word to be predcited since '<BOS>' will be given\n",
    "for i in range(len(tokenized_outputs)):\n",
    "    tokenized_outputs[i] = tokenized_outputs[i][1:]\n",
    "# pad and create a matrix based on vocabulary\n",
    "padded_outputs = pad_sequences(tokenized_outputs, maxlen = maxlen_outputs, padding = 'post')\n",
    "decoder_output_data = to_categorical(padded_outputs, vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seq2Seq Model with Attention for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 256)    3078144     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 256)    3078144     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, None, 256),  525312      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 256),  525312      embedding_1[0][0]                \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "dot (Dot)                       (None, None, None)   0           lstm_1[0][0]                     \n",
      "                                                                 lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, None, None)   0           dot[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, None, 256)    0           activation[0][0]                 \n",
      "                                                                 lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, None, 512)    0           dot_1[0][0]                      \n",
      "                                                                 lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, None, 12024)  6168312     concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 13,375,224\n",
      "Trainable params: 13,375,224\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# encoder model with LSTM layer with 256 units, returning outputs and states\n",
    "enc_inputs = Input(shape=(None,))\n",
    "enc_embedding = Embedding(vocab_size, 256, mask_zero = True)(enc_inputs)\n",
    "enc_lstm = LSTM(256, return_sequences = True, return_state = True)\n",
    "enc_outputs, enc_state_h, enc_state_c = enc_lstm(enc_embedding)\n",
    "enc_states = [enc_state_h, enc_state_c]\n",
    "enc_outputs = enc_outputs\n",
    "\n",
    "# decoder model with LSTM layer with 256 units, returning outputs and states\n",
    "dec_inputs = Input(shape = (None,))\n",
    "dec_embedding = Embedding(vocab_size, 256, mask_zero = True)(dec_inputs)\n",
    "dec_lstm = LSTM(256, return_state = True, return_sequences = True)\n",
    "dec_outputs, dec_state_h, dec_state_c = dec_lstm(dec_embedding, initial_state = enc_states)\n",
    "\n",
    "# connect decoder and encoder outputs to generate an attention vector with softmax applied\n",
    "attention = dot([dec_outputs, enc_outputs], axes = [2, 2])\n",
    "attention = Activation('softmax')(attention)\n",
    "# connect the attention vector and encoder outputs to generate context vector\n",
    "context = dot([attention, enc_outputs], axes = [2, 1])\n",
    "# connect context vector and decoder outputs to use as input for dense layer\n",
    "dec_attention_outputs = concatenate([context, dec_outputs])\n",
    "\n",
    "# use decoder outputs concatenated with the context vector to output final prediction\n",
    "dec_dense = TimeDistributed(Dense(vocab_size, activation = 'softmax'))\n",
    "output = dec_dense(dec_attention_outputs)\n",
    "\n",
    "# generate and compile model\n",
    "model = Model([enc_inputs, dec_inputs], output)\n",
    "model.compile(optimizer = \"adam\", loss = 'categorical_crossentropy', metrics = [\"accuracy\"])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "239/239 [==============================] - 241s 978ms/step - loss: 1.9137 - accuracy: 0.1445\n",
      "Epoch 2/10\n",
      "239/239 [==============================] - 238s 994ms/step - loss: 1.4429 - accuracy: 0.2189\n",
      "Epoch 3/10\n",
      "239/239 [==============================] - 236s 984ms/step - loss: 1.3595 - accuracy: 0.2533\n",
      "Epoch 4/10\n",
      "239/239 [==============================] - 238s 995ms/step - loss: 1.3027 - accuracy: 0.2686\n",
      "Epoch 5/10\n",
      "239/239 [==============================] - 237s 992ms/step - loss: 1.2496 - accuracy: 0.2781\n",
      "Epoch 6/10\n",
      "239/239 [==============================] - 239s 1s/step - loss: 1.1990 - accuracy: 0.2859\n",
      "Epoch 7/10\n",
      "239/239 [==============================] - 235s 984ms/step - loss: 1.1632 - accuracy: 0.2932\n",
      "Epoch 8/10\n",
      "239/239 [==============================] - 238s 995ms/step - loss: 1.1182 - accuracy: 0.2994\n",
      "Epoch 9/10\n",
      "239/239 [==============================] - 239s 1000ms/step - loss: 1.0624 - accuracy: 0.3098\n",
      "Epoch 10/10\n",
      "239/239 [==============================] - 240s 1s/step - loss: 1.0133 - accuracy: 0.3264\n"
     ]
    }
   ],
   "source": [
    "# fit model with 20% validation\n",
    "history = model.fit([encoder_input_data, decoder_input_data], decoder_output_data, \n",
    "                    batch_size = 64, epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seq2Seq Model for Inference using Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder model using inputs and outputs defined above\n",
    "enc_model = Model(enc_inputs, [enc_outputs, enc_states])\n",
    "\n",
    "# set intputs to receive encoder model states output by enc_model\n",
    "decoder_initial_state_h = Input(shape = (256, ))\n",
    "decoder_initial_state_c = Input(shape = (256, ))\n",
    "decoder_initial_states = [decoder_initial_state_h, decoder_initial_state_c]\n",
    "# lstm layer is defined again to set up with decoder_inital_states variable because this will change \n",
    "# as predictions more forward\n",
    "decoder_outputs, decoder_state_h, decoder_state_c = dec_lstm(dec_embedding , initial_state = decoder_initial_states)\n",
    "decoder_states = [decoder_state_h, decoder_state_c]\n",
    "# decoder model using lstm layer defined above in trained model with variabled defined\n",
    "dec_model = Model([dec_inputs, decoder_initial_states], [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample Chatbot using Inference Model with Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You: Hey\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: yes \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You: Are you free?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i am sorry i am sorry i am sorry i am sorry i am not a little of a few years ago \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You: that made no sense\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i am not going to be a little hour \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You: you know the deal?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i do not know \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You: you have to say something smart\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i am not a good teacher \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You: that's not good\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: well i am not going to be a little \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You: useless\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i am sorry \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You: quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Bye\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    # take user input\n",
    "    userinput = input('You:')\n",
    "    # if input is 'quit', return 'bye'\n",
    "    if userinput == 'quit':\n",
    "        print('Bot: ' + 'Bye')\n",
    "        break\n",
    "    \n",
    "    # preprocess user input\n",
    "    userinput = replace_text(userinput)\n",
    "    userinput = tokenizer.texts_to_sequences([userinput])\n",
    "    userinput = pad_sequences(userinput, maxlen = maxlen_inputs, padding = 'post')\n",
    "    \n",
    "    # return encoder outputs and states for given user input\n",
    "    encoder_outputs, encoder_states = enc_model.predict(userinput)\n",
    "    \n",
    "    # initialize current word as '<bos>' and encoder states as initial input states\n",
    "    current_word = '<bos>'\n",
    "    current_input_states = encoder_states\n",
    "    predicted_output = ''\n",
    "\n",
    "    for i in range(maxlen_outputs):\n",
    "        # transform current word to vocab index\n",
    "        empty_target_seq = np.zeros((1, 1))\n",
    "        empty_target_seq[0, 0] = tokenizer.word_index[current_word]\n",
    "        \n",
    "        # return decoder outputs and states for current word and current states\n",
    "        decoder_outputs, decoder_state_h, decoder_state_c = dec_model.predict([empty_target_seq] + current_input_states)\n",
    "        \n",
    "        # derive context and predict next word using decoder output with attention\n",
    "        attention_output = dot([decoder_outputs, encoder_outputs], axes=[2,2])\n",
    "        attention_output = Activation('softmax')(attention_output)\n",
    "        context_output = dot([attention_output, encoder_outputs], axes=[2,1])\n",
    "        dec_attention = concatenate([context_output, decoder_outputs])\n",
    "        final_output1 = dec_dense(dec_attention)\n",
    "\n",
    "        # find the predicted word \n",
    "        for word, idx in tokenizer.word_index.items():\n",
    "            if idx == np.argmax(final_output1):\n",
    "                next_word = word\n",
    "\n",
    "        # change the current word and current states\n",
    "        current_word = next_word\n",
    "        current_input_states = [decoder_state_h, decoder_state_c]\n",
    "\n",
    "        # break if '<eos>' is predicted\n",
    "        if next_word == '<eos>':\n",
    "            break\n",
    "        else:\n",
    "            predicted_output += next_word + ' '\n",
    "\n",
    "    print(\"Bot: \" + predicted_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion and Future Direction\n",
    "\n",
    "During this project, we learnt that a seq2seq model with attention required lots of data and processing power to train. Despite the attention mechanism implemented, the lack of training and the subset of data selected did not allow the model to perform well. Furthermore, there was no hyperparameter tuning done to the model due to the hardware requirements. Our goal with this set up was to get the model to try produce \"proper\" sentence, which it was able to do to some extent. Also, it is nearly impossible to obtain a human-human like conversation with a chatbot due to the use of a movie lines dataset.\n",
    "\n",
    "#### Future Direction\n",
    "- Better hardware to use all available data and train for more epochs, or learn to progressively train the model\n",
    "- Obtain realistic training data, not movie lines\n",
    "- BERT embeddings weights used instead of generated own embeddings\n",
    "- Learn and attempt to implement hierarchical neural attention encoder\n",
    "- Test Transformer architecture chatbot and compare results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References:\n",
    "\n",
    "[1]: Dataset collect and information about Cornell movie dialog corpus dataset; Available: https://www.cs.cornell.edu/ cristian/CornellMovieDialogsCorpus.htm\n",
    "\n",
    "[2]: Seq2Seq AI Chatbot with Attention Mechanism; Abonia Sojasingarayar; [Paper] Available: https://arxiv.org/ftp/arxiv/papers/2006/2006.02767.pdf\n",
    "\n",
    "[3]: Sequence to Sequence Learning with Neural Networks; Ilya Sutskever, Oriol Vinyals, Quoc V. Le; [Paper] Available: https://arxiv.org/pdf/1409.3215v3.pdf\n",
    "\n",
    "[4]: Effective Approaches to Attention-based Neural Machine Translation; Minh-Thang Luong, Hieu Pham, Christopher D. Manning; [Paper] Available: https://arxiv.org/pdf/1508.04025.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
